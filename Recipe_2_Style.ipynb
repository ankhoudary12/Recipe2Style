{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The Purpose of This Notebook Will be to highlight all the Steps Required to Make the Recipe 2 Style App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Collection-Selenium & Yummly API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "import os\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def inf_scroll(scrolls=1000):\n",
    "    \n",
    "    '''This function imitiates a user infinitely scrolling to the bottom of a webpage'''\n",
    "\n",
    "    loop_counter = 0\n",
    "    #driver.get(\"http://www.museodelprado.es/coleccion/obras-de-arte\")\n",
    "    #time.sleep(5)\n",
    "    while loop_counter < scrolls:\n",
    "        #     driver.execute_script(\"window.scrollTo(0, 300)\")\n",
    "        #     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        scroll = driver.find_element_by_tag_name('body')\n",
    "        scroll.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(1)\n",
    "        if loop_counter%100 == 0:\n",
    "            print(loop_counter)\n",
    "        loop_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "driver.get('https://www.yummly.com/recipes?sortBy=relevance&allowedCuisine=cuisine%5Ecuisine-barbecue-bbq') \n",
    "#do this for all desired cuisine types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inf_scroll(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "element=driver.find_elements_by_xpath('//div[@class=\"RecipeContainer\"]/div/a')\n",
    "barbeque_recipes=[x.get_attribute('href') for x in element ]    \n",
    "import pickle\n",
    "with open('barbeque.pickle', 'wb') as f:\n",
    "    pickle.dump(barbeque_recipes, f)\n",
    "    \n",
    "###repeat for all the necessary regional cuisine styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Get Recipe Data From Yummly API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cuisines= [\n",
    "    'barbeque',\n",
    "    'british',\n",
    "    'cajun',\n",
    "    'chinese',\n",
    "    'cuban',\n",
    "    'french',\n",
    "    'german',\n",
    "    'greek',\n",
    "    'hawaiian',\n",
    "    'hungarian',\n",
    "    'indian',\n",
    "    'irish',\n",
    "    'italian',\n",
    "    'japanese',\n",
    "    'keto',\n",
    "    'mexican',\n",
    "    'moroccan',\n",
    "    'paleo',\n",
    "    'portuguese',\n",
    "    'southwestern',\n",
    "    'spanish',\n",
    "    'swedish',\n",
    "    'thai',\n",
    "    'vegan',\n",
    "    'vietnamese'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "recipes=[]\n",
    "for item in cuisines: ###load all the recipes from the pickles\n",
    "    with open(item+'.pickle','rb') as p:\n",
    "        l=pickle.load(p)\n",
    "        print(item)\n",
    "        recipes.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yummly_recipes=[] #make the recipe urls amenable to the yummly api\n",
    "for item in recipes:\n",
    "    for x in item:\n",
    "        yummly_recipes.append(x.replace('https://www.yummly.com/recipe/', ''))B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yummly_recipes.remove('https://www.yummly.com/page/hellmanns') #weird that it grabbed this one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for link in yummly_recipes: #grab info from the yummly api\n",
    "    try:\n",
    "        response=requests.get('http://api.yummly.com/v1/api/recipe/'+link+'?_app_id=MYAPPID&_app_key=MYAPPKEY')\n",
    "        yummly_responses.append(response.json())\n",
    "        print(link)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('yummly_responses.pickle', 'wb') as f:\n",
    "    pickle.dump(yummly_responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yummly_data=[] #Get all the data we want from the Yummly API\n",
    "for response in yummly_responses:\n",
    "    recipe_dict={}\n",
    "    try:\n",
    "        recipe_dict['name']=response['id']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['yummly_url']=response['attribution']['url']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['recipe_url']=response['source']['sourceRecipeUrl']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['cuisine']=response['attributes']['cuisine'][0]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['cook_time']=response['cookTimeInSeconds']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['prep_time']=response['prepTimeInSeconds']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['rating']=response['rating']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['ingredients']=response['ingredientLines']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['image']=response['images'][0]['hostedLargeUrl']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for item in response['nutritionEstimates']:\n",
    "            if item['attribute']=='ENERC_KCAL':\n",
    "                 recipe_dict['calories']=item['value']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for x in response['nutritionEstimates']:\n",
    "            if x['attribute']=='PROCNT':\n",
    "                recipe_dict['protein']=x['value']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "         for x in response['nutritionEstimates']:\n",
    "            if x['attribute']=='CHOCDF':\n",
    "                recipe_dict['carbs']=x['value']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for x in response['nutritionEstimates']:\n",
    "            if x['attribute']=='FAT':\n",
    "                recipe_dict['fat']=x['value']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for x in response['nutritionEstimates']:\n",
    "            if x['attribute']=='SUGAR':\n",
    "                recipe_dict['sugar']=x['value']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for x in response['nutritionEstimates']:\n",
    "            if x['attribute']=='NA':\n",
    "                recipe_dict['sodium']=x['value']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for x in response['nutritionEstimates']:\n",
    "            if x['attribute']=='FIBTG':\n",
    "                recipe_dict['fiber']=x['value']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['bitter']=response['flavors']['Bitter']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['meaty']=response['flavors']['Meaty']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['piquant']=response['flavors']['Piquant']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['salty']=response['flavors']['Salty']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['sour']=response['flavors']['Sour']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        recipe_dict['sweet']=response['flavors']['Sweet']\n",
    "    except:\n",
    "        pass\n",
    "    yummly_data.append(recipe_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(yummly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df.to_pickle('yummly_dataframe.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Yummly Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_pickle('cuisine_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='yummly_url', inplace=True) #get rid of duplicate columns\n",
    "df.dropna(subset=['bitter'], inplace=True) #get rid of any recipes that don't have recipe data \n",
    "df.drop('cuisine_x',axis=1,inplace=True) #we want only our custom cuisine type\n",
    "df.drop(['cook_time','prep_time'], axis=1, inplace=True) #too many missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re #now to clean up some strings \n",
    "df['name_clean']=df.apply(lambda x: re.sub(r'[0-9]+', '', x['name']),axis=1) ###get rid of recipe id \n",
    "df['name_clean']=df.apply(lambda x: re.sub(r'-+', ' ',x['name_clean']),axis=1) ### clean up dashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### now lets replace NaN images with random stock images \n",
    "image_url='http://4.bp.blogspot.com/-1PPIpuTPnPY/UCudijf1DPI/AAAAAAAABgY/Ohzq0co9uyk/s1600/generic.jpg'\n",
    "df['image'].fillna(value=image_url, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### replace null nutrition information with mean of that column\n",
    "df['calories'].fillna(value=df['calories'].mean(), inplace=True)\n",
    "\n",
    "df['carbs'].fillna(value=df['carbs'].mean(), inplace=True)\n",
    "\n",
    "df['fat'].fillna(value=df['fiber'].mean(), inplace=True)\n",
    "\n",
    "df['fiber'].fillna(value=df['fiber'].mean(), inplace=True)\n",
    "\n",
    "df['protein'].fillna(value=df['protein'].mean(), inplace=True)\n",
    "\n",
    "df['sodium'].fillna(value=df['sodium'].mean(), inplace=True)\n",
    "\n",
    "df['sugar'].fillna(value=df['sugar'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Now we need to clean up the ingredients, (get rid of 2 cups, 1 oz shredded, etc)\n",
    "#Luckily Someone has made a handy table already!!!\n",
    "food_stop_words='''1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "7\n",
    "8\n",
    "9\n",
    "10\n",
    "tsp\n",
    "t\n",
    "a\n",
    "oz\n",
    "with\n",
    "extra\n",
    "tbs\n",
    "i\n",
    "e\n",
    "o\n",
    "if\n",
    "on\n",
    "at\n",
    "tb\n",
    "s\n",
    "fra\n",
    "de\n",
    "g\n",
    "kg\n",
    "lb\n",
    "powdered\n",
    "of\n",
    "light\n",
    "ground\n",
    "sauce\n",
    "fresh\n",
    "aged\n",
    "quality\n",
    "scant\n",
    "use\n",
    "generous\n",
    "pastry\n",
    "bag\n",
    "diameter\n",
    "tip\n",
    "duty\n",
    "plus\n",
    "stuffed\n",
    "slivered\n",
    "blanched\n",
    "unsalted\n",
    "flakes\n",
    "thaw\n",
    "thawed\n",
    "plumped\n",
    "one\n",
    "two\n",
    "three\n",
    "four\n",
    "five\n",
    "six\n",
    "seven\n",
    "eight\n",
    "nine\n",
    "ten\n",
    "cup\n",
    "teaspoon\n",
    "cups\n",
    "heavy\n",
    "duty\n",
    "stand\n",
    "mixer\n",
    "then\n",
    "any\n",
    "reserved\n",
    "for\n",
    "another\n",
    "measured\n",
    "measure\n",
    "about\n",
    "preferably\n",
    "fine\n",
    "quality\n",
    "well\n",
    "roughly\n",
    "rough\n",
    "do\n",
    "not\n",
    "additional\n",
    "pan\n",
    "inch_diameter\n",
    "inch\n",
    "diameter\n",
    "reserved\n",
    "ounce\n",
    "chopped\n",
    "tablespoons\n",
    "ground\n",
    "and\n",
    "to\n",
    "taste\n",
    "fresh\n",
    "teaspoons\n",
    "or\n",
    "can\n",
    "sliced\n",
    "powder\n",
    "pound\n",
    "all\n",
    "package\n",
    "minced\n",
    "diced\n",
    "into\n",
    "chunks\n",
    "cup\n",
    "dry\n",
    "uncooked\n",
    "peeled\n",
    "and\n",
    "the\n",
    "in\n",
    "cubes\n",
    "inch\n",
    "to\n",
    "taste\n",
    "chopped\n",
    "cups\n",
    "tsp\n",
    "tablespoon\n",
    "tbsp\n",
    "quart\n",
    "sliced\n",
    "into\n",
    "torn\n",
    "stemmed\n",
    "minced\n",
    "cracked\n",
    "rings\n",
    "whole\n",
    "strips\n",
    "bunch\n",
    "sprigs\n",
    "fresh\n",
    "cut\n",
    "pinch\n",
    "pound\n",
    "finely\n",
    "seeded\n",
    "as\n",
    "needed\n",
    "need\n",
    "chunks\n",
    "juiced\n",
    "soaked\n",
    "soak\n",
    "overnight\n",
    "low\n",
    "optional\n",
    "piece\n",
    "head\n",
    "large\n",
    "small\n",
    "cored\n",
    "medium\n",
    "such\n",
    "cover\n",
    "pitted\n",
    "halved\n",
    "quartered\n",
    "package\n",
    "packages\n",
    "grated\n",
    "separated\n",
    "florets\n",
    "softened\n",
    "half\n",
    "medium\n",
    "freshly\n",
    "of\n",
    "halves\n",
    "beaten\n",
    "cooked\n",
    "leaves\n",
    "needed\n",
    "pieces\n",
    "crushed\n",
    "extra\n",
    "pitted\n",
    "flavored\n",
    "unsweetened\n",
    "prepared\n",
    "light\n",
    "jar\n",
    "black\n",
    "red\n",
    "ones\n",
    "branches\n",
    "plain\n",
    "stick\n",
    "pot\n",
    "cube\n",
    "ripe\n",
    "baby\n",
    "vac\n",
    "semi\n",
    "gem\n",
    "paste\n",
    "chunks\n",
    "quartered\n",
    "seasoned\n",
    "sweetened\n",
    "thin\n",
    "flaked\n",
    "rolled\n",
    "canned\n",
    "mashed\n",
    "garnish\n",
    "french\n",
    "evaporated\n",
    "liquid\n",
    "lengthwise\n",
    "sifted\n",
    "wedges\n",
    "puree\n",
    "pure\n",
    "pint\n",
    "quarts\n",
    "squares\n",
    "undrained\n",
    "chilled\n",
    "raw\n",
    "separated\n",
    "c\n",
    "zested\n",
    "hard\n",
    "frozen\n",
    "drained\n",
    "rinsed\n",
    "squeezed\n",
    "welfare\n",
    "x\n",
    "g\n",
    "ml\n",
    "sticks\n",
    "higher\n",
    "spatchcocked\n",
    "free\n",
    "range\n",
    "bite\n",
    "sized\n",
    "bone\n",
    "boneless\n",
    "breast\n",
    "bunches\n",
    "cans\n",
    "coarsely\n",
    "container\n",
    "cooking\n",
    "cream\n",
    "crumbled\n",
    "crumbs\n",
    "cubed\n",
    "dash\n",
    "dashes\n",
    "decoration\n",
    "degrees\n",
    "divided\n",
    "dredging\n",
    "dried\n",
    "dusting\n",
    "envelope\n",
    "extract\n",
    "f\n",
    "filling\n",
    "fine\n",
    "finely\n",
    "fluid\n",
    "frying\n",
    "heavy\n",
    "hot\n",
    "hulled\n",
    "instant\n",
    "jars\n",
    "juice\n",
    "lean\n",
    "lightly\n",
    "links\n",
    "matchstick\n",
    "matchsticks\n",
    "meat\n",
    "minced\n",
    "melted\n",
    "minutes\n",
    "mix\n",
    "mre\n",
    "ounces\n",
    "packed\n",
    "pounds\n",
    "or\n",
    "quick\n",
    "recipe\n",
    "refrigerated\n",
    "removed\n",
    "room\n",
    "sargento\n",
    "scrubbed\n",
    "seasoning\n",
    "seed\n",
    "sharp\n",
    "size\n",
    "skin\n",
    "skinless\n",
    "slices\n",
    "sodium\n",
    "sour\n",
    "stalk\n",
    "stock\n",
    "suce\n",
    "sweet\n",
    "temperature\n",
    "thick\n",
    "thinly\n",
    "toothpicks\n",
    "traditional\n",
    "trimmed\n",
    "vegetable\n",
    "warmed\n",
    "*\n",
    "oz\n",
    ",'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "food_stop_words=food_stop_words.split('\\n')\n",
    "def lower_case(row):\n",
    "    return [x.lower() for x in row]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['ingredients']=df['ingredients'].apply(lower_case) #make the ingredients lower case to remove with stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for ingredient in df['ingredients'][0]:\n",
    "    b=[]\n",
    "    temp_list=ingredient.split()\n",
    "    for item in temp_list:\n",
    "        if item not in food_stop_words:\n",
    "            b.append(item)\n",
    "            c=' '.join(b)\n",
    "    a.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_stop(row):\n",
    "    '''This function removes volumes and measurements and other miscellaneous stop words from the ingredient list'''\n",
    "    \n",
    "    import re\n",
    "    cleaned_ingredients=[]\n",
    "    \n",
    "    for ingredient in row:\n",
    "        temp_ingredient=[]\n",
    "        temp_list=ingredient.split()\n",
    "        \n",
    "        for item in temp_list:\n",
    "            if item not in food_stop_words and '(' not in item and ')' not in item and '1' not in item and '/' not in item:\n",
    "                item=re.sub(r'[0-9]+', '', item)\n",
    "                if item.isalpha:\n",
    "                    temp_ingredient.append(item)\n",
    "        \n",
    "        cleaned_ingredients.append(' '.join(temp_ingredient))\n",
    "        \n",
    "    return cleaned_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['ingredients']=df['ingredients'].apply(remove_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('clean_cuisine_df.pickle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Now we need to get a list of Standard food ingredients from the BBCs website\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Here is the scrapy code that was used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class ExampleSpider(scrapy.Spider):\n",
    "    name = 'bbc_ingredients_scraper'\n",
    "\n",
    "    custom_settings = {\n",
    "        \"DOWNLOAD_DELAY\": 3,\n",
    "        \"CONCURENT_REQUESTS_PER_DOMAIN\": 3,\n",
    "        \"HTTPCACHE_ENABLED\": True,\n",
    "        'ROBOTSTXT_OBEY': False\n",
    "    }\n",
    "\n",
    "    start_urls = ['https://www.bbc.com/food/ingredients']\n",
    "\n",
    "    def parse(self, response):\n",
    "\n",
    "        for link in response.xpath('//ol[@class=\"resource-nav\"]/li/a/@href').extract()[:25]:\n",
    "\n",
    "            yield scrapy.Request(\n",
    "                url='https://www.bbc.com'+link,\n",
    "                callback=self.parse_bbc\n",
    "            )\n",
    "\n",
    "    def parse_bbc(self, response):\n",
    "\n",
    "        ingredients = response.xpath('//li[@class=\"resource food\"]/@id').extract()\n",
    "\n",
    "        yield {\n",
    "        'ingredients':ingredients\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2=pd.read_json('bbc_ingredient/bbc_ingredients.json') #read in a list of bbc ingredients to standardize against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bbc_ingredients=[x for x in df2['ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bbc=[]\n",
    "for item in bbc_ingredients:\n",
    "    for ingred in item:\n",
    "        bbc.append(ingred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corrected=[]\n",
    "for item in bbc:\n",
    "    if '_' in item:\n",
    "        item=item.replace('_',' ')\n",
    "        corrected.append(item)\n",
    "    if 'coriander' in item:\n",
    "        item=item.replace('coriander','cilantro')\n",
    "        corrected.append(item)\n",
    "    if 'aubergine' in item:\n",
    "        item=item.replace('aubergine','eggplant')\n",
    "    else:\n",
    "        corrected.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bbc_ingredients=set(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_pickle('clean_cuisine_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def match_ingredient(row):\n",
    "    corrected_ingredients=[]\n",
    "    for item in row:\n",
    "        corrected_ingredient=get_closest_match(item,bbc_ingredients)\n",
    "        if corrected_ingredient == None:\n",
    "            corrected_ingredient='salt'\n",
    "        corrected_ingredients.append(corrected_ingredient)\n",
    "    return corrected_ingredients\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def correct_None(row):\n",
    "    corrected_ingredients=[]\n",
    "    for item in row:\n",
    "        if item == None:\n",
    "            corrected_ingredient='salt'\n",
    "        else:\n",
    "            corrected_ingredient=item\n",
    "        corrected_ingredients.append(corrected_ingredient)\n",
    "    return corrected_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['ingredients']=df['ingredients'].apply(match_ingredient)\n",
    "df['ingredients']=df['ingredients'].apply(correct_None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('clean_cuisine_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Now we need to Build out the Word2Vec Model and t-SNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_pickle('clean_cuisine_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ingredients=[x for x in df['ingredients']]bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gensim  # using skip-gram\n",
    "model = gensim.models.Word2Vec(ingredients, size=300, window=4, min_count=1, workers=2) ##set parameters for word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.most_similar('cheddar cheese', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_w2v_score(row):\n",
    "    '''This function will take a recipe and return the average of all ingredient vecotrs'''\n",
    "    import numpy as np\n",
    "    \n",
    "    ingredient_scores=[]\n",
    "    \n",
    "    for item in row:\n",
    "        ingredient_score=np.mean(model[item])\n",
    "        ingredient_scores.append(ingredient_score)\n",
    "    \n",
    "    return np.mean(ingredient_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['recipe_score']=df['ingredients'].apply(get_w2v_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ing=df[['ingredients','cuisine_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_recipe_vec(l):\n",
    "    \n",
    "    count=0\n",
    "    matrix_addition=np.zeros(300)\n",
    "    \n",
    "    for item in l:\n",
    "        count+=1\n",
    "        \n",
    "        matrix_addition+=np.array(model[item])\n",
    "        \n",
    "    return (matrix_addition/count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ing['recipe_vec']=df_ing['ingredients'].apply(get_recipe_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x=[]\n",
    "for item in df_ing['recipe_vec'].values:\n",
    "    x.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300) #use t-SNE to reduce to 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results=tsne.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ing['x_tsne']=results[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ing['y_tsne']=results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Separate out the output into x,y components\n",
    "x = df_ing['x_tsne']\n",
    "y = df_ing['y_tsne'\n",
    "\n",
    "topic = df_ing['cuisine_y'].unique()\n",
    "\n",
    "           #Select your color map, nipy_spectral is great for getting differentiated and readable colors\n",
    "cmap = matplotlib.cm.get_cmap('nipy_spectral')\n",
    "cmapScale = int(len(topics))\n",
    "\n",
    "#Rather than manually setting the sizes for everything, use the scale to keep everything in proportion\n",
    "figScale = 3\n",
    "\n",
    "plt.figure(figsize=(10*figScale, 10*figScale),facecolor='white')\n",
    "\n",
    "#For every topic, plot the points where that topic is the max and\n",
    "#find the topic center by taking the median location of all points associated\n",
    "#with the topic; draw a text box over it\n",
    "labels = [x for x in topics]\n",
    "for i in range(labels):\n",
    "    boolArr = np.array(labels) == i\n",
    "    plt.scatter(x[boolArr],y[boolArr],c=cmap(i*cmapScale),s=100)\n",
    "    x_avg = np.median(x[boolArr])\n",
    "    y_avg = np.median(y[boolArr])\n",
    "    plt.annotate(f'#{i+1}: {topics[i][0]}',\n",
    "                 xy=(x_avg, y_avg),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='center',\n",
    "                 va='center',\n",
    "                 fontsize=30,\n",
    "                 bbox=dict(boxstyle=\"round\", fc=\"whitesmoke\",alpha=0.9))\n",
    "plt.axis('off')\n",
    "plt.title('t-SNE Plot for Job Descriptions with 15 Topics',fontsize=10*figScale)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to Build the Final Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('final_recipes_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Building Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.set_index('name_clean', inplace=True)\n",
    "flavor_profile_df=df[['bitter','meaty','piquant','salty','sour','sweet','recipe_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dists=cosine_similarity(flavor_profile_df)\n",
    "sims_df2=pd.DataFrame(dists)\n",
    "\n",
    "sims_df2.index=flavor_profile_df.index\n",
    "\n",
    "sims_df2.columns=flavor_profile_df.index\n",
    "\n",
    "sims_df2.to_hdf('sims_df2.hdf','sims_df',mode='w')\n",
    "\n",
    "\n",
    "\n",
    "sims_df2 = pd.read_hdf('sims_df2.hdf','sims_df') #Need to use hdf format because file is too large for pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Now we will make a function to return the closest recipe matches for a particular cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_nearest_recipes(recipe, cuisine ,number=10):\n",
    "    \n",
    "    import pandas as pd\n",
    "\n",
    "    \n",
    "    import jellyfish\n",
    "\n",
    "    def get_closest_match(x, list_strings):\n",
    "\n",
    "        best_score= 0\n",
    "        best_match=None\n",
    "\n",
    "        for title in list_strings:\n",
    "\n",
    "            current_score=jellyfish.jaro_winkler(x, title)\n",
    "\n",
    "            if current_score > best_score:\n",
    "                best_score = current_score\n",
    "                best_match = title \n",
    "\n",
    "        return best_match\n",
    "    \n",
    "    recipe = get_closest_match(recipe, recipes_df.index)\n",
    "    \n",
    "    bool_array=[]\n",
    "    \n",
    "    for i in recipes_df['cuisine_y']:\n",
    "        \n",
    "        try:\n",
    "            bool_array.append(i==cuisine)\n",
    "        \n",
    "        except:\n",
    "            bool_array.append(None)\n",
    "            \n",
    "    bool_dict=dict(zip(recipes_df.index,bool_array))\n",
    "    \n",
    "    bool_df=pd.Series(bool_dict).to_frame()\n",
    "    \n",
    "    matching_recipes=sims_df.join(bool_df[bool_df[0]==True], how='inner')\n",
    "    \n",
    "    final_recipes=recipes_df.join(matching_recipes[recipe].sort_values()[1:number+1], how='inner')\n",
    "    \n",
    "    return final_recipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pack_recipes(df):\n",
    "        '''Will take resuls of finding nearest bars and return a list of bar dictionaries containing relevant info'''\n",
    "        \n",
    "        import operator\n",
    "        \n",
    "        recipes=[]\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            a=row.index\n",
    "            a={}\n",
    "            a['name']=row.index.capitalize()\n",
    "            a['image']=row['image']\n",
    "            a['meaty']=row['meaty']\n",
    "            a['piquant']=row['piquant']\n",
    "            a['salty']=row['salty']\n",
    "            a['sweet']=row['swett']\n",
    "            a['sour']=row['sour']\n",
    "            a['yummly_url']=row['yummly_url']\n",
    "            a['recipe_url']=row['recipe_url']\n",
    "            a['cuisine']=row['cuisine']\n",
    "            a['protein']=row['protein']\n",
    "            a['carbs']=row['carbs']\n",
    "            a['fat']=row['fat']\n",
    "            a['sugar']=row['sugar']\n",
    "            a['sodium']=row['sodium']\n",
    "            a['calories']=row['calories']\n",
    "\n",
    "            \n",
    "            recipes.append(a)\n",
    "\n",
    "        \n",
    "        return bars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### This is the final function for recommending similar cuisines based on cosine similarity of flavor vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def send_recipes(recipe, cuisine, number=9):    \n",
    "    \n",
    "    \n",
    "    def find_nearest_recipes(recipe, cuisine ,number=10):\n",
    "\n",
    "        import pandas as pd\n",
    "\n",
    "\n",
    "        import jellyfish\n",
    "\n",
    "        def get_closest_match(x, list_strings):\n",
    "\n",
    "            best_score= 0\n",
    "            best_match=None\n",
    "\n",
    "            for title in list_strings:\n",
    "\n",
    "                current_score=jellyfish.jaro_winkler(x, title)\n",
    "\n",
    "                if current_score > best_score:\n",
    "                    best_score = current_score\n",
    "                    best_match = title \n",
    "\n",
    "            return best_match\n",
    "\n",
    "        recipe = get_closest_match(recipe, recipes_df.index)\n",
    "\n",
    "\n",
    "        matching_recipes=sims_df.join(recipes_df[recipes_df['cuisine_y']==cuisine], how='inner')\n",
    "\n",
    "        final_recipes=recipes_df.join(matching_recipes[recipe].sort_values()[1:number+1], how='inner')\n",
    "\n",
    "        return final_recipes\n",
    "\n",
    "\n",
    "\n",
    "    def pack_recipes(df):\n",
    "            '''Will take resuls of finding nearest bars and return a list of bar dictionaries containing relevant info'''\n",
    "\n",
    "            import operator\n",
    "\n",
    "            recipes=[]\n",
    "\n",
    "            for index, row in df.iterrows():\n",
    "                a=row.index\n",
    "                a={}\n",
    "                a['name']=row['full_name']\n",
    "                a['image']=row['image']\n",
    "                a['meaty']=row['meaty']\n",
    "                a['piquant']=row['piquant']\n",
    "                a['salty']=row['salty']\n",
    "                a['sweet']=row['sweet']\n",
    "                a['sour']=row['sour']\n",
    "                a['yummly_url']=row['yummly_url']\n",
    "                a['recipe_url']=row['recipe_url']\n",
    "                a['cuisine']=row['cuisine_y']\n",
    "                a['protein']=row['protein']\n",
    "                a['carbs']=row['carbs']\n",
    "                a['fat']=row['fat']\n",
    "                a['sugar']=row['sugar']\n",
    "                a['sodium']=row['sodium']\n",
    "                a['calories']=row['calories']\n",
    "\n",
    "\n",
    "                recipes.append(a)\n",
    "\n",
    "\n",
    "            return recipes\n",
    "        \n",
    "    return pack_recipes(find_nearest_recipes(recipe, cuisine, number))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
